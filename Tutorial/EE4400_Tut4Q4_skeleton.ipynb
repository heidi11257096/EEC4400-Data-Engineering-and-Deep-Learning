{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9uTM0whag4a"
   },
   "source": [
    "# **EE4400 - Tutorial 4 Q4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdddQO_Aat2F"
   },
   "source": [
    "This question is on handwritten digit image classification using a convolutional neural network (CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHX9gv8BLG8b"
   },
   "outputs": [],
   "source": [
    "# To determine which version you're using:\n",
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMufwafDYPl8"
   },
   "source": [
    "We shall use the Tensorflow package which contains the Keras sub-package to implement the CNN. The dataset is the MNIST dataset found within Keras.\n",
    "Import the necessary packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6JH-NfKcWZa"
   },
   "source": [
    "*Acknowledgement*: Refer to https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/ for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8N-V0DDproN"
   },
   "outputs": [],
   "source": [
    "## baseline cnn model for mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGfXuoqweKqo"
   },
   "source": [
    "A function to load the training and test datasets. Reshape the inputs to be in a single channel, and convert the outputs to one-hot-encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MN-9-M1wp9h9"
   },
   "outputs": [],
   "source": [
    "## load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-MYD1Ebewwa"
   },
   "source": [
    "A function to prepare (convert integers to floats) and scale pixels (so that range is [0,1]) in the input images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ig6H41DrfHTS"
   },
   "outputs": [],
   "source": [
    "## scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCSoZiYRe12r"
   },
   "source": [
    "Write a function define_model() to define the CNN model. Set up a CNN network with 16 filters each of size (3,3) followed by a 2D max pooling layer of pooling size (2,2). Add a dense layer of 50 nodes before the output with 10 nodes (i.e., 1 node per digit). Use the SGD optimizer and the categorical cross entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OK90DROTfFre"
   },
   "outputs": [],
   "source": [
    "## define cnn model\n",
    "def define_model():\n",
    "  # [WriteCode]\n",
    "  # :\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fpBKMmwfeLE"
   },
   "source": [
    "Write a function 'evaluate_model(dataX, dataY, n_folds=5)' to evaluate a model through n-fold cross-validation using the sklearn.model_selection function 'KFold()'. The define_model(), model.fit() and model.evaluate() functions are used. The 'evaluate_model()' function returns the 'scores' and 'histories', which are lists of accuracy values and model statistics, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLP405r3qESG"
   },
   "outputs": [],
   "source": [
    "## evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "  scores, histories = list(), list()\n",
    "  # prepare cross validation\n",
    "  kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "  # enumerate splits\n",
    "  for train_ix, test_ix in kfold.split(dataX):\n",
    "    # define model\n",
    "    # [WriteCode]\n",
    "    # select rows for train and test\n",
    "    # [WriteCode]\n",
    "    # fit model\n",
    "    # [WriteCode]\n",
    "    # evaluate model\n",
    "    # [WriteCode]\n",
    "    # store scores\n",
    "    # [WriteCode]\n",
    "  return scores, histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZckVfPMrf4SM"
   },
   "source": [
    "Write a function to plot the learning curves of cross entropy loss and classification accuracy, using 'histories' as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v3lOk4rqKEo"
   },
   "outputs": [],
   "source": [
    "## plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tpyplot.subplot(2, 1, 1)\n",
    "\t\tpyplot.title('Cross Entropy Loss')\n",
    "    # [WriteCode]\n",
    "\t\t# plot accuracy\n",
    "\t\tpyplot.subplot(2, 1, 2)\n",
    "\t\tpyplot.title('Classification Accuracy')\n",
    "    # [WriteCode]\n",
    "\tpyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDFvaO01gpQs"
   },
   "source": [
    "A function to summarize the model performance using a box plot of the accuracy values, using 'scores' as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qa2PbEQyhQ5-"
   },
   "outputs": [],
   "source": [
    "## summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7li9u-jxh2Pg"
   },
   "source": [
    "Write the main processing steps that calls the functions defined above to do the following steps:\n",
    "(i) load the dataset, \n",
    "(ii) prepare pixel data, \n",
    "(iii) evaluate model, \n",
    "(iv) plot learning curves, and\n",
    "(v) summarize estimated performance.\n",
    "Note: the evaluate_model() function may take a few minutes (on Colab with GPU acceleration; longer without GPU acceleration) to run since the network and data are fairly large, and a lot of processing is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyd7808KqUYu"
   },
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "\n",
    "## main processing\n",
    "\n",
    "# load dataset\n",
    "trainX, trainY, testX, testY = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZqxjxK_i5dt"
   },
   "outputs": [],
   "source": [
    "# prepare pixel data\n",
    "trainX, testX = prep_pixels(trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H8zXKDOrwSQ",
    "outputId": "9a750b85-270b-4c6b-a118-ce9453a1e1e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18BStbGii5zO"
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "scores, histories = evaluate_model(trainX, trainY)\n",
    "print(scores)\n",
    "print(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swA3Pup6i6Ed"
   },
   "outputs": [],
   "source": [
    "# learning curves\n",
    "summarize_diagnostics(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmefWD3li6X1"
   },
   "outputs": [],
   "source": [
    "# summarize estimated performance\n",
    "summarize_performance(scores)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EE4802-Tut4Q4-skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
